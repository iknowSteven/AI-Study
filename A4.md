# 데이터셋 오류의 종류

데이터셋 오류의 종류는 다음과 같이 구분할 수 있습니다.

#### 나쁜 데이터의 사례
1. 대표성 없는 훈련 데이터
2. 낮은 품질의 데이터
3. 관련 없는 특성

#### 나쁜 알고리즘의 사례
4. 훈련 데이터 과대적합
5. 훈련 데이터 과소적합
<br/><br/><br/>

## 대표성 없는 훈련 데이터
일반화가 잘 되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요합니다.
<br/>
예를 들어 나이와 용돈의 관계를 데이터로 한 머신러닝 모델이 있다고 가정합시다. 일반적인 상황에서라면 나이가 어릴 수록 용돈이 적을 것입니다. 하지만, 나이가 어린데 용돈이 많은 데이터가 모델에 추가된다면, 모델이 크게 변경될 뿐만 아니라, 예측이 맞지 않게 됩니다.
<br/>
일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 중요합니다.
<hr/>

### Sampling noise(샘플링 잡음), Sampling bias(샘플링 편향)
대표성 없는 훈련 데이터의 사례로는 샘플링 잡음과 샘플링 편향이 있습니다.
#### 샘플링 잡음
샘플이 작아서, 우연에 의한 대표성 없는 데이터가 들어왔을 때
#### 샘플링 편향
표본 추출 방법이 잘못되어서 대표성을 띠지 못할 때
<hr/>
<br/><br/><br/>

## 낮은 품질의 데이터
Training data가 outlier(이상치), 잡음으로 가득찼다면, 머신러닝 시스템이 데이터셋의 패턴, 관계 등을 찾기 힘들 것입니다. 그렇기 때문에 훈련 데이터 정제에 많은 시간을 보내야합니다.
<br/>

#### 낮은 품질의 데이터가 들어왔을 때 다음과 같이 하는 것이 좋습니다.
1. 일부 샘플이 이상치라는 게 명확하면 그것을 수정하는 것이 좋습니다.
2. 일부 샘플에 특성 몇 개가 빠져있다면, 그것들을 무시할지, 빠진 값을 채울지 등을 정해야 합니다. 
<br/><br/><br/>

##  관련 없는 특성
성공적인 머신러닝 프로젝트를 하기 위해서는 훈련에 사용할 좋은 특성을 찾아야 합니다. 이러한 과정을 Feature engineering(특성 공학)이라고 합니다.
#### 특성 공학에는 다음이 포함됩니다.
1. 특성 선택
    가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택합니다.
2. 특성 추출
    특성을 결합하여 더 유용한 특성을 만듭니다. (차원 축소 알고리즘 활용)
3. 새로운 데이터를 수집하여 새 특성을 만듭니다.
<br/><br/><br/>

## 훈련 데이터 과대적합
#### 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 덜어질 때 훈련 데이터 과대적합이라고 합니다.
처음에는 이해가 안될 수도 있습니다. 이는 사례를 들어 설명하면 이해가 쉬울 것입니다.<br/>
외국인이 K-pop 비디오를 본다고 가정합시다. 그 외국인은 아마 모든 한국인들이 모두 잘생겼다고 생각할 것입니다. 영상에는 남자인 제가 봐도 정말 잘생긴 남자들이 많으니깐요.<br/>
하지만 **저같은 사람**이 있기 때문에 일반화가 되지 않습니다. 머신러닝도 같습니다. 제공된 샘플(K-pop 비디오)에는 너무 잘 들어맞지만 일반성은 떨어지게 됩니다.
#### 따라서 훈련 세트는 잡음이 없고 데이터가 많은 것이 좋습니다.
잡음이 많거나 데이터셋이 너무 작으면 잡음이 섞인 패턴을 감지하게 되며, 결국 일반화하지 못할 것입니다.
#### 과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어납니다. 이를 해결하는 방법은 다음과 같습니다.
    1. 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킵니다.
    2. 훈련 데이터를 더 많이 모읍니다.
    3. 훈련 데이터의 잡음을 줄입니다(오류 데이터 수정 및 이상치 제거)
<br/>

### 규제
#### 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 규제라고 합니다.
