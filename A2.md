# 머신러닝 시스템의 종류

머신러닝 시스템은 그 목적에 따라서 다양한 범주로 분류할 수 있습니다. 이 범주들은 서로 배타적이지 않으며 원하는 대로 연결할 수 있습니다.





## 지도 학습, 비지도 학습. 준지도 학습, 강화 학습

머신러닝 시스템을 학습하는 동안의 감독 형태나 정보량에 따라 구분하면 지도 학습, 비지도 학습, 준지도 학습, 강화 학습으로 구분할 수 있습니다. 쉽게 설명하면, 사람의 감독 하에 훈련하는 것인지 아닌지로 머신러닝을 구분하면 위와 같이 구분할 수 있습니다.



### Supervised learning(지도 학습)

지도 학습은 훈련 데이터에 Label(원하는 답)이 포함된 경우를 뜻합니다. Classification(분류)가 전형적인 지도학습의 예시이며, 스팸 필터가 지도학습을 통해 스팸을 구분합니다. 각 메일마다 이 것은 스팸이다, 저것은 스팸이 아니다를 훈련 데이터에 포함시켜 훈련시킵니다.

Regression(회귀)도 대표적인 지도 학습입니다. Regression을 할 땐, 예측 변수라 불리는 특성(Feature)을 조금씩 조정해가며 타겟의 수치를 예측합니다. 공부 시간에 따른 성적(Label) 예측, 주행거리에 따른 중고차 가격(Label) 예측 등이 여기에 들어가게 됩니다. 

다음은 가장 중요한 지도학습 알고리즘이며 뒤에서 다루겠습니다.

1. [ k-Nearest Neighbors, k-최근접 이웃]()

2. [Linear Regression, 선형 회귀]()
3. [Logistic Regression, 로지스틱 회귀]()
4. [Support Vector Machines(SVM), 서포트 벡터 머신]()
5. [Decision Tree & Random Forests, 결정 트리와 랜덤 포레스트]()
6. [Neural Networks, 신경망]()



### Unsupervised learning(비지도 학습)

지도 학습과 달리 비지도 학습은 훈련 데이터에 Label이 없습니다. 즉, 시스템이 아무런 도움 없이 학습해야 합니다. 이 때 인공지능은 데이터 사이의 연결고리를 스스로 찾습니다.

이를 활용하면 다음과 같습니다. 예를 들어, 쇼핑몰 방문자를 비슷한 그룹으로 묶기 위해 군집 알고리즘(비지도 학습)을 적용시킨다고 가정합시다. 하지만, 방문자가 어떤 그룹에 속하는지 알려줄 수 없습니다. 이런 경우에는 비지도 학습을 이용합니다. 비지도 학습 결과, 40%의 방문자가 댄디한 스타일을 좋아하며 저녁때 구입하는 남성이라는 결과를 도출했다면, 이 시간에는 댄디한 스타일의 남성복을 추천하는 광고를 띄우는 것이 쇼핑몰 매출에 도움이 될 것 입니다. 

다음은 가장 중요한 비지도 학습 알고리즘이며, 뒤에서 다루겠습니다.

1. **Clustering, 군집**

   1. [K-Means, K-평균]()

   2. [Hierachical Cluster Analysis, 계층 군집 분석]()

      계층 군집 분석을 사용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있습니다. 위와 같이 쇼핑몰 방문자를 비슷한 그룹으로 묶는 알고리즘이 이에 해당할 것입니다.

   3. [Expectation Maximization, 기댓값 최대화]()

2. **Visualiztion & Dimensionality reduction, 시각화와 차원 축소**

   Visualization(시각화)를 이용하면, Label이 없는 대규모의 고차원 데이터를 도식화가 가능한 2D나 3D 표현으로 보여줍니다. 이런 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로(입력 공간에서 떨어져 있는 데이터는 시각화된 그래프에서 겹쳐지지 않게 유지됩니다) 데이터가 어떻게 구성되어 있는지 이해할 수 있고, 예상하지 모한 패턴을 발견하는데 사용됩니다.

   너무 많은 정보를 잃지 않으면서 데이터를 간소화하기 위해서는 Dimenstionality reduction(차원 축소)를 이용합니다. 이를 위해 Feature extracton(특성추출-상관관계가 있는 여러 특성을 하나로 합치는 방법)을 이용합니다. 예를 들어 자동차의 주행거리, 연식, 엔진 수명이 데이터의 특성으로 제공되었다면, 주행거리와 엔진 수명은 매우 연관되어 있으므로 하나로 합칠 수 있습니다.

   Anomaly detection(이상치 탐지)도 비지도 학습의 중요한 예시 입니다. 부정 거래를 막기 위해 비정상적인 신용카드 거래를 감지하고, 공장에서 제조 결함을 잡아내는 것 등이 여기에 포함됩니다.

   인공지능 학습 알고리즘에 투입되는 데이터 셋 중 이상한 값을 자동으로 제거하는 것도 이상치 탐지인데, 시스템은 정상 샘플로 훈련되며, 새로운 샘플이 정상 데이터인지 아닌지 판단하게 됩니다.

   Association rule learning(연관 규칙 학습)도 널리 사용되는 비지도 학습입니다. 연관 규칙 학습을 이용한다면, 쇼핑몰에서 신발을 구입하는 사람이 양말도 구입한다는 경향을 발견할 수도 있습니다.

   1. [Principal Component Analysis(PCA), 주성분 분석]()
   2. [Kernel PCA, 커널 PCA]()
   3. [Locally-Linear Embedding(LLE), 지역적 선형 임베딩]()
   4. [t-distributed Stochastic Neighbor Embedding(t-SNE)]()

3. **Association rule learning, 연관 규칙 학습**

   1. [Apriori, 어프라이어리]()
   2. [Eclat, 이클랫]()



###준지도 학습

어떤 데이터는 Label이 있고 어떤 데이터는 없을 수도 있습니다. 이 때 이용하는 것이 준지도 학습입니다. 준지도 학습의 경우 보통 Label이 있는 데이터가 적고, 없는 데이터가 대부분입니다.

Google Photo 또는 iCloud Photo의 얼굴 인식 기능이 준지도 학습의 대표적인 예시입니다. 이 두 서비스에 사진을 올리면 비지도 학습을 통해 사람 A가 나온 사진과 사진 B가 나온 사진 등으로 묶습니다. 이는 비지도 학습(군집)입니다. 여기에 사람 A의 이름을 알려주면(Label), 서비스는 사진에 있는 모든 사람의 이름을 알 수 있고, 사용자는 편리하게 사진을 찾을 수 있게 됩니다.

이와 같이 대부분의 준지도 학습은 지도 학습과 비지도 학습의 조합으로 구성됩니다.



### 강화 학습

강화 학습은 지도 학습, 준지도 학습, 비지도 학습과는 매우 다른 종류의 알고리즘입니다. 강화 학습을 이해하는데는 개를 훈련시킨다고 생각하면 편리합니다.

개에게 배변 활동을 훈련시킨다고 가정합시다. 개가 배변 패드에 볼일을 보면 보상으로 간식을 주고, 다른 곳에서 배변을 보면 벌을 줍니다. 시간이 지나면 개는 보상을 받기 위해 배변 패드에 볼일을 봅니다.

인공지능도 마찬가지입니다. 여기서는 학습하는 시스템을 Agent(에이전트)라고 부르며, 환경을 관찰해서 행동을 실행하고 그 결과로 보상을, 또는 벌점을 받습니다. 시간이 지나면서 에이전트는 보상을 얻기 위해 Policy(정책)이라고 부르는 최상의 전략을 스스로 학습합니다. 이렇게 쌓인 정책은 추후에 에이전트가 어떻게 행동해야할지 선택하게 해주는 가이드가 됩니다.

보행 로봇을 만들 때 강화 학습을 많이 이용하며, 알파고 또한 강화 학습의 좋은 예시입니다. 알파고는 수백만 개의 게임을 분석해서 승리에 대한 전략을 학습했으며, 자신과 많은 게임을 통해 정책을 수정해나갔습니다. 그리고 이세돌과 게임할 때는 학습 기능을 끄고 그동안 학습했던 정책을 적용한 것입니다.





##온라인 학습, 배치학습

머신러닝은 시스템이 점진적으로 학습할 수 있는지 없는지에 따라 온라인 학습과 배치학습으로 구분할 수 있습니다.



###Batch learning(배치 학습)

배치 학습에서는 시스템이 점진적으로 학습할 수 없습니다. 즉 모든 데이터를 한번에 모두 사용해 훈련시켜야 합니다. 따라서 많은 시간과 자원을 소모하므로, 보통 오프라인에서 수행됩니다. 이런 경우, 메인 시스템을 훈련 시키고, 학습 결과를 제품 시스템에 적용하면 더 이상의 학습 없이 실행합니다. 이를 **Offline learning(오프라인 학습)**이라고 합니다.

배치 학습 시스템의 단점은, 새로운 데이터에 대해 학습하려면, 이전에 사용된 데이터 모두를 사용하여, 새로운 시스템의 버전을 다시 훈련시켜야 한다는 점입니다. 최근 들어, 머신 러닝 과정이 쉽게 자동화 될 수 있어서 개선되긴 했지만, 보통 24시간 또는 1주일마다 시스템을 훈련시켜야 하기 때문에, 더 능동적인 방법이 필요해 졌습니다.

또한 배치 학습은 더 많은 컴퓨팅 자원이 필요합니다. 그리고 데이터 셋이 많아지면 많아질수록 더 큰 비용이 발생하게 됩니다. 따라서 데이터 양이 많으면 온라인 학습을 하게 됩니다.



### Online learning(온라인 학습)

온라인 학습에서는 데이터를 순차적으로 하나씩 또는, Mini-batch(미니 배치)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킵니다. 데이터를 학습시키는 단위가 작기 때문에, 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있습니다. 따라서 빠른 변화에 스스로 적응해야 하는 시스템 또는 컴퓨팅 자원이 제한된 경우에 온라인 학습이 적합합니다.

온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지 않으므로 버리면 됩니다. 따라서 공간도 절약할 수 있다는 장점도 있습니다.

온라인 학습에서 중요한 Parameter 중 하나는 Learning rate 입니다. Learning rate가 높아지면 시스템이 새로운 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버리며, Learning rate가 낮아지면 시스템의 관성이 더 커져 더 느리게 학습될 것입니다. 하지만, 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해진다는 장점이 있습니다. 따라서 Learning rate를 적절하게 조정하는 것이 인공지능을 하는 사람에게 중요합니다.

온라인 학습의 가장 큰 문제는, 시스템에 나쁜 데이터가 투입되었을 때, 인공지능의 정확도가 점진적으로 감소한다는 것입니다. 이런 위험을 줄이려면 시스템을 계속 모니터링하고, 성능 감소가 감지되면 즉시 학습을 중지시켜야 합니다. 





##사례 기반 학습, 모델 기반 학습

머신 러닝 시스템은 어떻게 일반화되는 가에 따라, 즉 어떻게 예측을 만드는가에 따라 사례 기반 학습과 모델 기반 학습으로 나뉩니다.

###사레 기반 학습

사례 기반 학습은 시스템이 사례를 기억하믕로써 학습하는 방식입니다. 이 방식은 최악도, 최선도 아닌 방식입니다. 그 이유는. 데이터를 단순히 기억하는 것이기 때문입니다.

사례 기반 학습을 하기 위해서는 유사도를 측정해야 합니다. 어디 까지 같은 사례로 인정하냐는 것인데, 그 예로 스팸 메일 구분을 들 수 있습니다. 새로운 메일이 왔을 때, 공통으로 포함된 단어 수를 유사도로 사용한다면, 스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 구분합니다.

